{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1294774,"sourceType":"datasetVersion","datasetId":748575}],"dockerImageVersionId":29962,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Routine set up**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Import data**","metadata":{}},{"cell_type":"code","source":"path = '/kaggle/input/dataset/dataset.txt'\n\ndf = pd.read_csv(path)\n\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Now, we will continue with our example.","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\nfrom numpy import log\nresult = adfuller(df.value.dropna())\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Since p-value(1.00) is greater than the significance level(0.05), let’s difference the series and see how the autocorrelation plot looks like.","metadata":{}},{"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n\n\n# Original Series\nfig, axes = plt.subplots(3, 2, sharex=True)\naxes[0, 0].plot(df.value); axes[0, 0].set_title('Original Series')\nplot_acf(df.value, ax=axes[0, 1])\n\n# 1st Differencing\naxes[1, 0].plot(df.value.diff()); axes[1, 0].set_title('1st Order Differencing')\nplot_acf(df.value.diff().dropna(), ax=axes[1, 1])\n\n# 2nd Differencing\naxes[2, 0].plot(df.value.diff().diff()); axes[2, 0].set_title('2nd Order Differencing')\nplot_acf(df.value.diff().diff().dropna(), ax=axes[2, 1])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- For the above data, we can see that the time series reaches stationarity with two orders of differencing.\n\n","metadata":{}},{"cell_type":"code","source":"# PACF plot of 1st differenced series\nplt.rcParams.update({'figure.figsize':(9,3), 'figure.dpi':120})\n\nfig, axes = plt.subplots(1, 2, sharex=True)\naxes[0].plot(df.value.diff()); axes[0].set_title('1st Differencing')\naxes[1].set(ylim=(0,5))\nplot_pacf(df.value.diff().dropna(), ax=axes[1])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can see that the PACF lag 1 is quite significant since it is well above the significance line. So, we will fix the value of p as 1.","metadata":{}},{"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nplt.rcParams.update({'figure.figsize':(9,3), 'figure.dpi':120})\n\nfig, axes = plt.subplots(1, 2, sharex=True)\naxes[0].plot(df.value.diff()); axes[0].set_title('1st Differencing')\naxes[1].set(ylim=(0,1.2))\nplot_acf(df.value.diff().dropna(), ax=axes[1])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can see that couple of lags are well above the significance line. So, we will fix q as 2. If there is any doubt, we will go with the simpler model that sufficiently explains the Y.","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\n\n# 1,1,2 ARIMA Model\nmodel = ARIMA(df.value, order=(1,1,2))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The model summary provides lot of information. The table in the middle is the coefficients table where the values under ‘coef’ are the weights of the respective terms.\n\n- The coefficient of the MA2 term is close to zero and the P-Value in ‘P>|z|’ column is highly insignificant. It should ideally be less than 0.05 for the respective X to be significant.\n\n- So, we will rebuild the model without the MA2 term.","metadata":{}},{"cell_type":"code","source":"# 1,1,1 ARIMA Model\nmodel = ARIMA(df.value, order=(1,1,1))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The model AIC has slightly reduced, which is good. The p-values of the AR1 and MA1 terms have improved and are highly significant (<< 0.05).\n\n- Let’s plot the residuals to ensure there are no patterns (that is, look for constant mean and variance).","metadata":{}},{"cell_type":"code","source":"# Plot residual errors\nresiduals = pd.DataFrame(model_fit.resid)\nfig, ax = plt.subplots(1,2)\nresiduals.plot(title=\"Residuals\", ax=ax[0])\nresiduals.plot(kind='kde', title='Density', ax=ax[1])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The residual errors seem fine with near zero mean and uniform variance. Let’s plot the actuals against the fitted values using **plot_predict()**.","metadata":{}},{"cell_type":"code","source":"# Actual vs Fitted\nmodel_fit.plot_predict(dynamic=False)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- When we set dynamic=False the in-sample lagged values are used for prediction. That is, the model gets trained up until the previous value to make the next prediction. This can make the fitted forecast and actuals look artificially good.\n\n- So, we seem to have a decent ARIMA model. But, we can’t say that this is the best ARIMA model because we haven’t actually forecasted into the future and compared the forecast with the actual performance.\n\n- So, the real validation we need now is the Out-of-Time cross-validation, discussed next.","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.stattools import acf\n\n# Create Training and Test\ntrain = df.value[:85]\ntest = df.value[85:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Now, we will build the ARIMA model on training dataset, forecast and plot it.","metadata":{}},{"cell_type":"code","source":"# Build Model\n# model = ARIMA(train, order=(3,2,1))  \nmodel = ARIMA(train, order=(1, 1, 1))  \nfitted = model.fit(disp=-1)  \n\n# Forecast\nfc, se, conf = fitted.forecast(119, alpha=0.05)  # 95% conf\n\n# Make as pandas series\nfc_series = pd.Series(fc, index=test.index)\nlower_series = pd.Series(conf[:, 0], index=test.index)\nupper_series = pd.Series(conf[:, 1], index=test.index)\n\n# Plot\nplt.figure(figsize=(12,5), dpi=100)\nplt.plot(train, label='training')\nplt.plot(test, label='actual')\nplt.plot(fc_series, label='forecast')\nplt.fill_between(lower_series.index, lower_series, upper_series, \n                 color='k', alpha=.15)\nplt.title('Forecast vs Actuals')\nplt.legend(loc='upper left', fontsize=8)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- From the above chart, the ARIMA(1,1,1) model seems to predict a correct forecast. The actual observed values lie within the 95% confidence band. \n\n- But, we can see that the predicted forecasts is consistently below the actuals. That means, by adding a small constant to our forecast, the accuracy will certainly improve. \n\n- So, in this case, we should increase the order of differencing to two (d=2) and iteratively increase p and q up to 5 to see which model gives least AIC and also look for a chart that gives closer actuals and forecasts.\n\n- While doing this, I keep an eye on the P values of the AR and MA terms in the model summary. They should be as close to zero, ideally, less than 0.05.","metadata":{}},{"cell_type":"code","source":"# Build Model\nmodel = ARIMA(train, order=(3, 2, 1))  \nfitted = model.fit(disp=-1)  \nprint(fitted.summary())\n\n# Forecast\nfc, se, conf = fitted.forecast(119, alpha=0.05)  # 95% conf\n\n# Make as pandas series\nfc_series = pd.Series(fc, index=test.index)\nlower_series = pd.Series(conf[:, 0], index=test.index)\nupper_series = pd.Series(conf[:, 1], index=test.index)\n\n# Plot\nplt.figure(figsize=(12,5), dpi=100)\nplt.plot(train, label='training')\nplt.plot(test, label='actual')\nplt.plot(fc_series, label='forecast')\nplt.fill_between(lower_series.index, lower_series, upper_series, \n                 color='k', alpha=.15)\nplt.title('Forecast vs Actuals')\nplt.legend(loc='upper left', fontsize=8)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The AIC has reduced to 245 from 843 which is good. Mostly, the p-values of the X terms are less than < 0.05, which is great. So overall this model is much better.","metadata":{}},{"cell_type":"code","source":"# Accuracy metrics\ndef forecast_accuracy(forecast, actual):\n    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # MAPE\n    me = np.mean(forecast - actual)             # ME\n    mae = np.mean(np.abs(forecast - actual))    # MAE\n    mpe = np.mean((forecast - actual)/actual)   # MPE\n    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n    corr = np.corrcoef(forecast, actual)[0,1]   # corr\n    mins = np.amin(np.hstack([forecast[:,None], \n                              actual[:,None]]), axis=1)\n    maxs = np.amax(np.hstack([forecast[:,None], \n                              actual[:,None]]), axis=1)\n    minmax = 1 - np.mean(mins/maxs)             # minmax\n    acf1 = acf(fc-test)[1]                      # ACF1\n    return({'mape':mape, 'me':me, 'mae': mae, \n            'mpe': mpe, 'rmse':rmse, 'acf1':acf1, \n            'corr':corr, 'minmax':minmax})\n\nforecast_accuracy(fc, test.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Around 23.22% MAPE implies the model is about 76.78% accurate in predicting the next 15 observations. Now we know how to build an ARIMA model manually. \n\n- But, we should also know how to automate the best model selection process. So, we will discuss it next.\n\n","metadata":{}},{"cell_type":"code","source":"!pip install pmdarima","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\n\nimport pmdarima as pm\n\nmodel = pm.auto_arima(df.value, start_p=1, start_q=1,\n                      test='adf',       # use adftest to find optimal 'd'\n                      max_p=3, max_q=3, # maximum p and q\n                      m=1,              # frequency of series\n                      d=None,           # let model determine 'd'\n                      seasonal=False,   # No Seasonality\n                      start_P=0, \n                      D=0, \n                      trace=True,\n                      error_action='ignore',  \n                      suppress_warnings=True, \n                      stepwise=True)\n\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.plot_diagnostics(figsize=(10,8))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Forecast\nn_periods = 24\nfc, confint = model.predict(n_periods=n_periods, return_conf_int=True)\nindex_of_fc = np.arange(len(df.value), len(df.value)+n_periods)\n\n# make series for plotting purpose\nfc_series = pd.Series(fc, index=index_of_fc)\nlower_series = pd.Series(confint[:, 0], index=index_of_fc)\nupper_series = pd.Series(confint[:, 1], index=index_of_fc)\n\n# Plot\nplt.plot(df.value)\nplt.plot(fc_series, color='darkgreen')\nplt.fill_between(lower_series.index, \n                 lower_series, \n                 upper_series, \n                 color='k', alpha=.15)\n\nplt.title(\"Final Forecast of Usage\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/dataset/dataset.txt', parse_dates=['date'], index_col='date')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot\nfig, axes = plt.subplots(2, 1, figsize=(10,5), dpi=100, sharex=True)\n\n# Usual Differencing\naxes[0].plot(data[:], label='Original Series')\naxes[0].plot(data[:].diff(1), label='Usual Differencing')\naxes[0].set_title('Usual Differencing')\naxes[0].legend(loc='upper left', fontsize=10)\n\n\n# Seasonal Differencing\naxes[1].plot(data[:], label='Original Series')\naxes[1].plot(data[:].diff(12), label='Seasonal Differencing', color='green')\naxes[1].set_title('Seasonal Differencing')\nplt.legend(loc='upper left', fontsize=10)\nplt.suptitle('Drug Sales - Time Series Dataset', fontsize=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can see that, the seasonal spikes are intact after applying usual differencing (lag 1). Whereas, it is rectified after seasonal differencing.\n\n- Now, let’s build the SARIMA model using pmdarima‘s `auto_arima()`. To do so, we need to set seasonal=True, set the frequency m=12 for month wise series and enforce D=1.","metadata":{}},{"cell_type":"code","source":"# !pip3 install pyramid-arima (already done)\nimport pmdarima as pm\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seasonal - fit stepwise auto-ARIMA\nsmodel = pm.auto_arima(data, start_p=1, start_q=1,\n                         test='adf',\n                         max_p=3, max_q=3, m=12,\n                         start_P=0, seasonal=True,\n                         d=None, D=1, trace=True,\n                         error_action='ignore',  \n                         suppress_warnings=True, \n                         stepwise=True)\n\nsmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model has estimated the AIC and the P values of the coefficients look significant. Let’s look at the residual diagnostics plot.\n\nThe best model SARIMAX(3, 0, 0)x(0, 1, 1, 12) has an AIC of 528.6 and the P Values are significant.\n\nLet’s forecast for the next 24 months.","metadata":{}},{"cell_type":"code","source":"# Forecast\nn_periods = 24\nfitted, confint = smodel.predict(n_periods=n_periods, return_conf_int=True)\nindex_of_fc = pd.date_range(data.index[-1], periods = n_periods, freq='MS')\n\n# make series for plotting purpose\nfitted_series = pd.Series(fitted, index=index_of_fc)\nlower_series = pd.Series(confint[:, 0], index=index_of_fc)\nupper_series = pd.Series(confint[:, 1], index=index_of_fc)\n\n# Plot\nplt.plot(data)\nplt.plot(fitted_series, color='darkgreen')\nplt.fill_between(lower_series.index, \n                 lower_series, \n                 upper_series, \n                 color='k', alpha=.15)\n\nplt.title(\"SARIMA - Final Forecast of Drug Sales - Time Series Dataset\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There you have a nice forecast that captures the expected seasonal demand pattern.","metadata":{}},{"cell_type":"code","source":"# Compute Seasonal Index\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom dateutil.parser import parse\n\n# multiplicative seasonal component\nresult_mul = seasonal_decompose(data['value'][-36:],   # 3 years\n                                model='multiplicative', \n                                extrapolate_trend='freq')\n\nseasonal_index = result_mul.seasonal[-12:].to_frame()\nseasonal_index['month'] = pd.to_datetime(seasonal_index.index).month\n\n# merge with the base data\ndata['month'] = data.index.month\ndf = pd.merge(data, seasonal_index, how='left', on='month')\ndf.columns = ['value', 'month', 'seasonal_index']\ndf.index = data.index  # reassign the index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The exogenous variable (seasonal index) is ready. Let’s build the SARIMAX model.","metadata":{}},{"cell_type":"code","source":"import pmdarima as pm\n\n# SARIMAX Model\nsxmodel = pm.auto_arima(df[['value']], exogenous=df[['seasonal_index']],\n                           start_p=1, start_q=1,\n                           test='adf',\n                           max_p=3, max_q=3, m=12,\n                           start_P=0, seasonal=True,\n                           d=None, D=1, trace=True,\n                           error_action='ignore',  \n                           suppress_warnings=True, \n                           stepwise=True)\n\nsxmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[Go to Top](#0)","metadata":{}}]}